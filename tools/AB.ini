[All]
num-samples=100
[A]
model-path=../models/pytorch-16BIT-model_v5
temp=0.2
top-p=0.9
top-keks=0
repetition-penalty=1.1
top-p-first=True
#GPT2 can handle 1024 tokens, neo can handle 2048 IIRC
#Your GPU VRAM may limit it further of course
max-history-tokens=1024
[B]
model-path=../models/pytorch-16BIT-model_v5
temp=0.5
top-p=0.8
top-keks=0
repetition-penalty=1.1
top-p-first=True
max-history-tokens=1024
